{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91316154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading https://files.pythonhosted.org/packages/11/96/85b392e2564b69256b1d5360dd7d9e5428ea381623df590cfb45f3ea5432/pyspark-3.2.4.tar.gz (281.5MB)\n",
      "\u001b[K    8% |██▉                             | 25.1MB 120kB/s eta 0:35:32^C  2% |▊                               | 6.3MB 76kB/s eta 1:00:00    2% |█                               | 8.4MB 59kB/s eta 1:17:03    3% |█▎                              | 11.0MB 73kB/s eta 1:01:16    4% |█▋                              | 13.8MB 143kB/s eta 0:31:05    5% |█▋                              | 14.2MB 210kB/s eta 0:21:12    7% |██▍                             | 21.5MB 91kB/s eta 0:47:29\n",
      "\n",
      "\u001b[31mOperation cancelled by user\u001b[0m\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3150ebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialization\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/talentum/spark\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/bin/python3.6\" \n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/bin/python3\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")\n",
    "\n",
    "# NOTE: Whichever package you want mention here.\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0 pyspark-shell' \n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.3 pyspark-shell'\n",
    "# os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-xml_2.11:0.6.0,org.apache.spark:spark-avro_2.11:2.4.0 pyspark-shell'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "605dcb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrypoint 2.x\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "spark = SparkSession.builder.appName(\"Final Project\").enableHiveSupport().getOrCreate()\n",
    "\n",
    "# On yarn:\n",
    "# spark = SparkSession.builder.appName(\"Spark SQL basic example\").enableHiveSupport().master(\"yarn\").getOrCreate()\n",
    "# specify .master(\"yarn\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36eac3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click Here\n",
    "#Uname and UIds\n",
    "df_live_user_name=spark.read.format('parquet').load('file:///home/talentum/Project/ReviewDf_name/')\n",
    "#Restro Table\n",
    "df_only_restors=spark.read.format('parquet').load('file:///home/talentum/FinalTable/Parq/FBusinessPar.parquet')\n",
    "#User Table\n",
    "df_only_users=spark.read.format('parquet').load('file:///home/talentum/FinalTable/Parq/fuser.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaeed74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual Recomendations \n",
    "def get_top_n_recommendations(model,user_id, n=50):\n",
    "    recommendations = model.recommendProducts(user_id, n)\n",
    "    model = None  # Dereference the model\n",
    "    gc.collect()  # Force garbage collection to free up memory\n",
    "    \n",
    "    # Convert the recommendations to a list of Rows\n",
    "    rows = [Row(user_id=user_id, itemId_numeric=r.product, rating=r.rating) for r in recommendations]\n",
    "    \n",
    "    # Create a Spark DataFrame from the list of Rows\n",
    "    recommendations_df = spark.createDataFrame(rows)\n",
    "    \n",
    "    return recommendations_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e5dca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for filters and sorts \n",
    "def recomend_restros(model,user_id_numeric,u_state='',u_category='',u_nr=5):\n",
    "    # Get the top N recommendations for the user\n",
    "    recommendations_df = get_top_n_recommendations(model,user_id_numeric, n=50)\n",
    "\n",
    "    # Filter the main DataFrame using the recommendations\n",
    "    filtered_df = df_only_restors \\\n",
    "        .filter((col('state').rlike(f\"(?i).*{u_state}.*\"))& \n",
    "            (col('categories').rlike(f\"(?i).*{u_category}.*\")))\n",
    "\n",
    "    # Join the recommendations with the filtered DataFrame\n",
    "    result_df = filtered_df.join(recommendations_df, on='itemId_numeric', how='inner')\n",
    "\n",
    "    # Collect the top 5 results based on the rating\n",
    "    top_5_results = result_df.orderBy(col(\"rating\").desc()).limit(u_nr)\n",
    "\n",
    "    # Show the top 5 recommendations\n",
    "    top_5_results.select('itemId_numeric','name','address', 'city',\n",
    "     'state','categories','stars').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09e2ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_user(userId,uname):\n",
    "    from pyspark.sql.types import DoubleType, IntegerType, StructType, StructField,StringType\n",
    "    schema = StructType([\n",
    "    StructField(\"userId_numeric\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True)\n",
    "    ])\n",
    "    data = [(userId,uname)]\n",
    "    new_user_df = spark.createDataFrame(data, schema)\n",
    "    new_user_df.write.mode(\"append\").parquet(\"file:///home/talentum/Project/ReviewDf_name/\")\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "612db521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lets_rate(user_Id):\n",
    "    from pyspark.sql.types import DoubleType, IntegerType, StructType, StructField\n",
    "    #df_numeric=spark.read.format('parquet').load(\"file:///home/talentum/Project/ReviewDf/\")\n",
    "    #df_temp=df_numeric\n",
    "    #-\n",
    "    restro_Id=int(input(\"Select Restorant you Like (ID):\"))\n",
    "    \n",
    "    \n",
    "    df_r=df_only_restors.where(col('itemId_numeric')==int(restro_Id))\n",
    "    restro_name = df_r.select('name').collect()[0][0] \n",
    "    #-\n",
    "    u_stars=float(input(f\"Please Rate {restro_name}(out of 5):\"))\n",
    "    #Updating the df\n",
    "    \n",
    "    schema = StructType([\n",
    "    StructField(\"userId_numeric\", IntegerType(), True),\n",
    "    StructField(\"itemId_numeric\", IntegerType(), True),\n",
    "    StructField(\"stars\", DoubleType(), True)\n",
    "    ])\n",
    "    data = [(user_Id,restro_Id , u_stars)]\n",
    "    df_to_update=spark.createDataFrame(data,schema)\n",
    "\n",
    "    df_to_update.write.mode(\"append\").parquet(\"file:///home/talentum/Project/ReviewDf/\")\n",
    "    \n",
    "    print(\"Thanks For the rating... \")\n",
    "    retrain_model()\n",
    "    print(\"---Model_Saved---\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e057e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain_model():\n",
    "    from pyspark.mllib.recommendation import ALS, Rating\n",
    "    from pyspark.sql.functions import col\n",
    "    df_live=spark.read.format('parquet').load(\"file:///home/talentum/Project/ReviewDf/\")\n",
    "    ratings = df_live.rdd.map(lambda row: Rating(row[\"userId_numeric\"], row[\"itemId_numeric\"], row[\"stars\"]))\n",
    "     \n",
    "    model_path = 'file:///home/talentum/Project/Model1'\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "    # Delete the existing model directory\n",
    "        shutil.rmtree(model_path)\n",
    "    \n",
    "    \n",
    "    # Train ALS model\n",
    "    rank = 10\n",
    "    numIterations = 10\n",
    "    block_size=-1 # parallel computing\n",
    "    model1 = ALS.train(ratings, rank, numIterations,blocks=block_size)\n",
    "    print(\"---Model_Trained---\")\n",
    "    #rf_model.write().overwrite().save(rf_model_path)\n",
    "    model1.save(spark.sparkContext, model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fd16eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5():\n",
    "    print(\"---------------------Top Rated Places ----------------------\")\n",
    "    top_5_results = df_only_restors.orderBy(col(\"stars\").desc()).select('itemId_numeric','name','address', 'city',\n",
    "    'state','categories','stars').limit(5)\n",
    "    top_5_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eacff766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your User  Id (existing user)/ alphabate for new user :77\n",
      "Welcome Back Eliot !\n",
      "---------------------Top Rated Places ----------------------\n",
      "+--------------+--------------------+-----------------+------------+-----+--------------------+-----+\n",
      "|itemId_numeric|                name|          address|        city|state|          categories|stars|\n",
      "+--------------+--------------------+-----------------+------------+-----+--------------------+-----+\n",
      "|         36081|    The Mad Griddle |   2127 E 10th St|Indianapolis|   IN|Arts & Entertainm...|  5.0|\n",
      "|         64655|          The Office|     248 W 1st St|        Reno|   NV|Nightlife, Lounge...|  5.0|\n",
      "|           191|     The Pepper Pott| 4611 Alabama Ave|   Nashville|   TN|Caribbean, Food, ...|  5.0|\n",
      "|         47614|       Mr. Margarita|    Truck Inn Way|     Fernley|   NV|   Food Trucks, Food|  5.0|\n",
      "|         58054|The Music Box Vil...|4557 N Rampart St| New Orleans|   LA|Local Flavor, Pub...|  5.0|\n",
      "+--------------+--------------------+-----------------+------------+-----+--------------------+-----+\n",
      "\n",
      "---------------------Top 5 Recommendations for you---------------------\n",
      "+--------------+--------------------+--------------------+-----------+-----+--------------------+-----+\n",
      "|itemId_numeric|                name|             address|       city|state|          categories|stars|\n",
      "+--------------+--------------------+--------------------+-----------+-----+--------------------+-----+\n",
      "|         19751|         Diggs Pizza|      4646 S Cole Rd|      Boise|   ID|  Pizza, Restaurants|  4.5|\n",
      "|         45487|New Orleans Drink...|      343 Baronne St|New Orleans|   LA|Venues & Event Sp...|  5.0|\n",
      "|         53936|Famous Fat Freddi...|      1432 E High St|  Pottstown|   PA|  Pizza, Restaurants|  2.0|\n",
      "|         55357|Tommy G's Pizzeri...|901 Convention Ce...|New Orleans|   LA|Food, Food Delive...|  3.5|\n",
      "|         30359|         Ellendale's|2739 Old Elm Hill...|  Nashville|   TN|Southern, America...|  3.0|\n",
      "+--------------+--------------------+--------------------+-----------+-----+--------------------+-----+\n",
      "\n",
      "Select Restorant you Like (ID):53936\n",
      "Please Rate Famous Fat Freddie's Pizza(out of 5):4.5\n",
      "Thanks For the rating... \n",
      "---Model_Trained---\n",
      "---Model_Saved---\n",
      "-----------------------------------------------------------------------\n",
      "We  Are Ready...\n",
      "---------------------Top 5 Recommendations for you---------------------\n",
      "+--------------+--------------------+--------------------+----------------+-----+--------------------+-----+\n",
      "|itemId_numeric|                name|             address|            city|state|          categories|stars|\n",
      "+--------------+--------------------+--------------------+----------------+-----+--------------------+-----+\n",
      "|         25622|   ReAnimator Coffee|     310 W Master St|    Philadelphia|   PA|  Coffee & Tea, Food|  4.5|\n",
      "|         57896|     Taqueria Olvera|       341 Market Pl|Fairview Heights|   IL|Restaurants, Mexican|  4.5|\n",
      "|         63130|         Chick-fil-A|241 Westshore Plz...|           Tampa|   FL|Fast Food, Restau...|  3.0|\n",
      "|         63934|Super Value Beverage|       625 Mearns Rd|      Warminster|   PA|Food, Beer, Wine ...|  4.0|\n",
      "|         36096|             Dunkin'|7454 Lancaster Pi...|       Hockessin|   DE|Food, Coffee & Te...|  2.0|\n",
      "+--------------+--------------------+--------------------+----------------+-----+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to get top 50 recomendation RETURNS A DF OBJECT\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StructType, StructField\n",
    "#og user 234659\n",
    "user_Id=input(\"Enter your User  Id (existing user)/ alphabate for new user :\")\n",
    "if(user_Id.isdigit() and  df_live_user_name.filter(col('userId_numeric').isin([int(user_Id)])).count() > 0):\n",
    "    \n",
    "    \n",
    "    path ='file:///home/talentum/Project/Model'\n",
    "\n",
    "    from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "    model = MatrixFactorizationModel.load(sc, path)\n",
    "    # Get recommendations from the model\n",
    "    \n",
    "    df_u_all=spark.read.format('parquet').load(\"file:///home/talentum/Project/ReviewDf_name/\")\n",
    "    df_user=df_u_all.where(col('userId_numeric')==int(user_Id))\n",
    "    user_name = df_user.select(\"name\").collect()[0][0] \n",
    "    user_Id=int(user_Id)\n",
    "    print(f\"Welcome Back {user_name} !\")\n",
    "    \n",
    "    \n",
    "    top_5()\n",
    "    \n",
    "    \n",
    "    print(\"---------------------Top 5 Recommendations for you---------------------\")\n",
    "    recomend_restros(model,user_id_numeric=user_Id)\n",
    "    lets_rate(user_Id)\n",
    "    \n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    \n",
    "    path = 'file:///home/talentum/Project/Model1'\n",
    "    \n",
    "    from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "    model1 = MatrixFactorizationModel.load(sc, path)\n",
    "    print(\"We  Are Ready...\")\n",
    "    #ustate=input(\"Enter Your state(0  for none ):\")\n",
    "    #if(ustate=='0'):\n",
    "    #    ustate=''\n",
    "    print(\"---------------------Top 5 Recommendations for you---------------------\")\n",
    "    recomend_restros(model1,user_id_numeric=user_Id)#,u_state=ustate)\n",
    "    \n",
    "    \n",
    "    \n",
    "else :\n",
    "    df_numeric=spark.read.format('parquet').load(\"file:///home/talentum/Project/ReviewDf/\")\n",
    "    print(\"---------------------Id Generated for you---------------------\")\n",
    "    #-\n",
    "    max_Id = df_numeric.agg({\"userId_numeric\": \"max\"}).collect()[0]\n",
    "    new_Id=max_Id[\"max(userId_numeric)\"]+1\n",
    "    print(f\"Your Id is :{new_Id}\")\n",
    "    uname=input(\"Enter Your name:\")\n",
    "    new_user(new_Id,uname)\n",
    "    \n",
    "    top_5()\n",
    "    \n",
    "    lets_rate(int(new_Id))\n",
    "    \n",
    "    print(\"-----------------------------------------------------------------------\")\n",
    "    \n",
    "    path = 'file:///home/talentum/Project/Model1'\n",
    "    \n",
    "    from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "    model1 = MatrixFactorizationModel.load(sc, path)\n",
    "    \n",
    "    print(\"---------------------Top 5 Recommendations for you---------------------\")\n",
    "    recomend_restros(model1,user_id_numeric=new_Id)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb9d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97085e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25634df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc57b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7958ec27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92916bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ee00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0529a6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8facf9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91c87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971f67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefbb476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea57bbb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd6285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff5aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e9720d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870c44a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e2e5fef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+\n",
      "|userId_numeric|name|\n",
      "+--------------+----+\n",
      "+--------------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_u_all=spark.read.format('parquet').load(\"file:///home/talentum/Project/ReviewDf_name/\")\n",
    "df_u_all.where(col('userId_numeric')==234660).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36608b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommentation():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
